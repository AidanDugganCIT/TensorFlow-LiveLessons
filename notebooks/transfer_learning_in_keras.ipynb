{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning in Keras\n",
    "\n",
    "In this notebook, we'll cover how to load a pre-trained model (in this case, VGGNet19) and finetune it for a new task: detecting hot dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pre-trained VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(include_top=False,\n",
    "              weights='imagenet',\n",
    "              input_shape=(224,224,3),\n",
    "              pooling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze all the layers in the base VGGNet19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add custom classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the sequential model and add the VGG19 model: \n",
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "\n",
    "# Add the custom layers atop the VGG19 model: \n",
    "model.add(Flatten(name='flattened'))\n",
    "model.add(Dropout(0.5, name='dropout'))\n",
    "model.add(Dense(2, activation='softmax', name='predictions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = 'model_output/transfer_VGG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                 \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available for download [here](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/home). You should download the zipfile and extract the contents into a folder called `hot-dog-not-hot-dog` in the `notebooks` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate two image generator classes:\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    data_format='channels_last',\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    data_format='channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the batch size:\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the train and validation generators: \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='./hot-dog-not-hot-dog/train',\n",
    "    target_size=(224, 224),\n",
    "    classes=['hot_dog','not_hot_dog'],\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory='./hot-dog-not-hot-dog/test',\n",
    "    target_size=(224, 224),\n",
    "    classes=['hot_dog','not_hot_dog'],\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "15/15 [==============================] - 27s - loss: 0.9057 - acc: 0.5708 - val_loss: 0.9379 - val_acc: 0.5771\n",
      "Epoch 2/16\n",
      "15/15 [==============================] - 5s - loss: 0.7060 - acc: 0.7055 - val_loss: 0.5858 - val_acc: 0.7115\n",
      "Epoch 3/16\n",
      "15/15 [==============================] - 4s - loss: 0.6657 - acc: 0.7076 - val_loss: 0.7819 - val_acc: 0.6708\n",
      "Epoch 4/16\n",
      "15/15 [==============================] - 4s - loss: 0.4218 - acc: 0.8135 - val_loss: 0.4329 - val_acc: 0.7906\n",
      "Epoch 5/16\n",
      "15/15 [==============================] - 4s - loss: 0.3648 - acc: 0.8571 - val_loss: 0.4473 - val_acc: 0.7927\n",
      "Epoch 6/16\n",
      "15/15 [==============================] - 4s - loss: 0.3965 - acc: 0.8159 - val_loss: 0.4762 - val_acc: 0.7799\n",
      "Epoch 7/16\n",
      "15/15 [==============================] - 4s - loss: 0.3415 - acc: 0.8472 - val_loss: 0.5320 - val_acc: 0.7500\n",
      "Epoch 8/16\n",
      "15/15 [==============================] - 4s - loss: 0.2863 - acc: 0.8738 - val_loss: 0.4313 - val_acc: 0.7927\n",
      "Epoch 9/16\n",
      "15/15 [==============================] - 4s - loss: 0.2898 - acc: 0.8769 - val_loss: 0.5657 - val_acc: 0.7479\n",
      "Epoch 10/16\n",
      "15/15 [==============================] - 4s - loss: 0.2878 - acc: 0.8613 - val_loss: 0.4165 - val_acc: 0.8098\n",
      "Epoch 11/16\n",
      "15/15 [==============================] - 4s - loss: 0.3322 - acc: 0.8497 - val_loss: 0.4638 - val_acc: 0.7991\n",
      "Epoch 12/16\n",
      "15/15 [==============================] - 4s - loss: 0.2492 - acc: 0.8932 - val_loss: 0.5278 - val_acc: 0.7756\n",
      "Epoch 13/16\n",
      "15/15 [==============================] - 4s - loss: 0.2329 - acc: 0.9114 - val_loss: 0.4408 - val_acc: 0.8034\n",
      "Epoch 14/16\n",
      "15/15 [==============================] - 4s - loss: 0.2750 - acc: 0.8586 - val_loss: 0.6302 - val_acc: 0.7521\n",
      "Epoch 15/16\n",
      "15/15 [==============================] - 4s - loss: 0.2598 - acc: 0.8863 - val_loss: 0.5553 - val_acc: 0.7714\n",
      "Epoch 16/16\n",
      "15/15 [==============================] - 4s - loss: 0.3513 - acc: 0.8467 - val_loss: 1.0363 - val_acc: 0.6838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88f2be7400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=15, \n",
    "                    epochs=16, validation_data=valid_generator, \n",
    "                    validation_steps=15, callbacks=[modelcheckpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
